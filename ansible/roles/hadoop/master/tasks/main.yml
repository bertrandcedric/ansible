---
- template:
    src: "{{item}}"
    dest: "/usr/local/hadoop/etc/hadoop/{{item}}"
  with_items:
    - masters
    - slaves

- file:
    path: /usr/local/hadoop_store/hdfs/namenode
    owner: deploy
    group: deploy
    state: directory
  become: yes

- fetch:
    src: /home/deploy/.ssh/id_rsa.pub
    dest: "{{workspace}}/fetch"

#- copy:
#    src: hadoop-mapreduce-examples-2.7.3.jar
#    dest: /tmp/hadoop-mapreduce-examples-2.7.3.jar
#    owner: deploy
#    group: deploy

- shell: start-dfs.sh
  args:
    chdir: "/home/deploy"
    executable: /bin/bash
  register: logStartDfs
  changed_when: logStartDfs.stdout.find('starting datanode') != -1

- debug:
    var: logStartDfs.stdout_lines
